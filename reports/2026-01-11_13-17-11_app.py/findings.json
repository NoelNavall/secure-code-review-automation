{
  "scan_date": "2026-01-11 13:17:32",
  "total_findings": 10,
  "summary": {
    "CRITICAL": 3,
    "HIGH": 3,
    "MEDIUM": 4,
    "LOW": 0
  },
  "findings": [
    {
      "tool": "bandit",
      "severity": "CRITICAL",
      "title": "hardcoded_sql_expressions",
      "message": "Possible SQL injection vector through string-based query construction.",
      "file": ".\\.\\sample\\app.py",
      "line": 27,
      "code": "26     cursor = conn.cursor()\n27     query = f\"SELECT * FROM users WHERE username='{username}' AND password='{password}'\"\n28     cursor.execute(query)  # BUG: Direct string interpolation\n",
      "cwe": [
        89
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "CRITICAL",
      "title": "hardcoded_sql_expressions",
      "message": "Possible SQL injection vector through string-based query construction.",
      "file": ".\\.\\sample\\app.py",
      "line": 89,
      "code": "88     cursor = conn.cursor()\n89     cursor.execute(f\"DELETE FROM users WHERE id={user_id}\")\n90     conn.commit()\n",
      "cwe": [
        89
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "CRITICAL",
      "title": "hardcoded_sql_expressions",
      "message": "Possible SQL injection vector through string-based query construction.",
      "file": ".\\.\\sample\\app.py",
      "line": 126,
      "code": "125     # Storing password in plaintext\n126     cursor.execute(f\"INSERT INTO users VALUES ('{username}', '{password}')\")  # BUG: No hashing\n127     conn.commit()\n",
      "cwe": [
        89
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "HIGH",
      "title": "subprocess_popen_with_shell_equals_true",
      "message": "subprocess call with shell=True identified, security issue.",
      "file": ".\\.\\sample\\app.py",
      "line": 41,
      "code": "40     # Vulnerable to command injection\n41     result = subprocess.check_output(f\"ping -c 1 {host}\", shell=True)  # BUG: shell=True with user input\n42     return result\n",
      "cwe": [
        78
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "HIGH",
      "title": "hashlib",
      "message": "Use of weak MD5 hash for security. Consider usedforsecurity=False",
      "file": ".\\.\\sample\\app.py",
      "line": 78,
      "code": "77     # Vulnerable: Using MD5 for security\n78     hashed = hashlib.md5(data.encode()).hexdigest()  # BUG: MD5 is cryptographically broken\n79     return hashed\n",
      "cwe": [
        327
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "HIGH",
      "title": "flask_debug_true",
      "message": "A Flask app appears to be run with debug=True, which exposes the Werkzeug debugger and allows the execution of arbitrary code.",
      "file": ".\\.\\sample\\app.py",
      "line": 156,
      "code": "155     # VULNERABILITY: Debug mode in production\n156     app.run(debug=True, host='0.0.0.0')  # BUG: debug=True exposes stack traces\n",
      "cwe": [
        94
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "MEDIUM",
      "title": "blacklist",
      "message": "Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.",
      "file": ".\\.\\sample\\app.py",
      "line": 68,
      "code": "67     # Vulnerable to insecure deserialization\n68     obj = pickle.loads(data)  # BUG: Unpickling untrusted data\n69     return str(obj)\n",
      "cwe": [
        502
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "MEDIUM",
      "title": "request_without_timeout",
      "message": "Call to requests without timeout",
      "file": ".\\.\\sample\\app.py",
      "line": 101,
      "code": "100     # Vulnerable to SSRF\n101     response = requests.get(url)  # BUG: No URL validation\n102     return response.text\n",
      "cwe": [
        400
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "MEDIUM",
      "title": "blacklist",
      "message": "Using xml.etree.ElementTree.fromstring to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.fromstring with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is called",
      "file": ".\\.\\sample\\app.py",
      "line": 151,
      "code": "150     # Vulnerable to XXE\n151     tree = ET.fromstring(xml_data)  # BUG: No XXE protection\n152     return tree.text\n",
      "cwe": [
        20
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    },
    {
      "tool": "bandit",
      "severity": "MEDIUM",
      "title": "hardcoded_bind_all_interfaces",
      "message": "Possible binding to all interfaces.",
      "file": ".\\.\\sample\\app.py",
      "line": 156,
      "code": "155     # VULNERABILITY: Debug mode in production\n156     app.run(debug=True, host='0.0.0.0')  # BUG: debug=True exposes stack traces\n",
      "cwe": [
        605
      ],
      "llm_analysis": {
        "raw_response": "Error calling LM Studio: 'choices'"
      }
    }
  ]
}